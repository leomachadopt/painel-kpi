// @ts-nocheck
import express from 'express'
import multer from 'multer'
import path from 'path'
import fs from 'fs'
import { fileURLToPath } from 'url'
import OpenAI from 'openai'
import { v4 as uuidv4 } from 'uuid'
import pool from '../db.js'
import { authRequired } from '../middleware/auth.js'
import { pdfToPng } from 'pdf-to-png-converter'
import Tesseract from 'tesseract.js'
// pdf-to-img importado dinamicamente apenas quando necess√°rio para evitar erros em ambiente serverless

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const router = express.Router()

// Configure multer for PDF uploads
// Use memory storage for serverless (Vercel) compatibility
const isServerless = !!process.env.VERCEL || !!process.env.AWS_LAMBDA_FUNCTION_NAME

const storage = isServerless
  ? multer.memoryStorage()
  : multer.diskStorage({
      destination: (req, file, cb) => {
        const uploadDir = path.join(__dirname, '../../public/uploads/insurance-pdfs')
        if (!fs.existsSync(uploadDir)) {
          fs.mkdirSync(uploadDir, { recursive: true })
        }
        cb(null, uploadDir)
      },
      filename: (req, file, cb) => {
        const uniqueName = `${uuidv4()}-${Date.now()}${path.extname(file.originalname)}`
        cb(null, uniqueName)
      }
    })

const upload = multer({
  storage,
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'application/pdf') {
      cb(null, true)
    } else {
      cb(new Error('Apenas arquivos PDF s√£o permitidos'))
    }
  },
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB
  }
})

// Initialize OpenAI (only if API key is available)
let openai: OpenAI | null = null
try {
  if (process.env.OPENAI_API_KEY) {
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    })
  } else {
    console.warn('‚ö†Ô∏è OPENAI_API_KEY not configured. PDF processing will not be available.')
  }
} catch (error) {
  console.error('‚ùå Failed to initialize OpenAI client:', error)
}

/**
 * POST /api/insurance/:providerId/upload-pdf
 * Upload and process PDF to extract procedures
 */
router.post('/:providerId/upload-pdf', authRequired, upload.single('pdf'), async (req, res) => {
  const client = await pool.connect()

  try {
    const { providerId } = req.params
    const { clinicId } = req.body
    const uploadedFile = req.file

    console.log('üì§ Upload PDF iniciado:', { providerId, clinicId, file: uploadedFile?.originalname })

    if (!uploadedFile) {
      return res.status(400).json({ error: 'Nenhum arquivo PDF enviado' })
    }

    if (!clinicId) {
      return res.status(400).json({ error: 'clinicId √© obrigat√≥rio' })
    }

    // Verify provider belongs to clinic
    const providerCheck = await client.query(
      'SELECT id, name FROM insurance_providers WHERE id = $1 AND clinic_id = $2',
      [providerId, clinicId]
    )

    if (providerCheck.rows.length === 0) {
      // Clean up uploaded file (only if using disk storage)
      if (uploadedFile.path) {
        try {
          fs.unlinkSync(uploadedFile.path)
        } catch (err) {
          console.error('Error deleting file:', err)
        }
      }
      return res.status(404).json({ error: 'Operadora n√£o encontrada' })
    }

    const provider = providerCheck.rows[0]

    // Create document record
    const documentId = uuidv4()
    console.log('üìù Criando registro de documento:', documentId)

    await client.query(
      `INSERT INTO insurance_provider_documents (
        id, insurance_provider_id, file_name, file_path, file_size, mime_type,
        processed, processing_status, created_by
      ) VALUES ($1, $2, $3, $4, $5, $6, false, 'PROCESSING', $7)`,
      [
        documentId,
        providerId,
        uploadedFile.originalname,
        uploadedFile.path || 'memory',
        uploadedFile.size,
        uploadedFile.mimetype,
        req.user.id
      ]
    )

    console.log('‚úÖ Documento registrado, iniciando processamento em background')

    // Process PDF in background
    // Pass buffer if using memory storage, path if using disk storage
    const fileData = uploadedFile.buffer || uploadedFile.path
    processPDFDocument(documentId, fileData, providerId, clinicId, provider.name, uploadedFile.originalname)
      .catch(err => {
        console.error('‚ùå Error processing PDF:', err)
      })

    res.json({
      success: true,
      documentId,
      message: 'PDF enviado com sucesso. Processamento iniciado.'
    })

  } catch (error) {
    console.error('Error uploading PDF:', error)

    // Clean up uploaded file on error (only if using disk storage)
    if (req.file && req.file.path) {
      try {
        fs.unlinkSync(req.file.path)
      } catch (err) {
        console.error('Error deleting file:', err)
      }
    }

    res.status(500).json({ error: 'Erro ao fazer upload do PDF' })
  } finally {
    client.release()
  }
})

/**
 * Update processing progress
 */
async function updateProgress(documentId: string, progress: number, stage: string) {
  try {
    await pool.query(
      `UPDATE insurance_provider_documents
       SET processing_progress = $1, processing_stage = $2
       WHERE id = $3`,
      [progress, stage, documentId]
    )
  } catch (error) {
    console.error('Error updating progress:', error)
  }
}

/**
 * Process PDF document with OpenAI Vision API
 */
async function processPDFDocument(
  documentId: string,
  fileData: Buffer | string,
  providerId: string,
  clinicId: string,
  providerName: string,
  fileName: string
) {
  const client = await pool.connect()

  try {
    console.log('üîÑ Iniciando processamento do PDF:', { documentId, providerId, providerName })
    await updateProgress(documentId, 5, 'CONVERTING')

    // Check if OpenAI is available
    if (!openai) {
      console.error('‚ùå OpenAI client not initialized (missing API key)')
      await client.query(
        `UPDATE insurance_provider_documents
         SET processing_status = 'FAILED',
             processed_at = CURRENT_TIMESTAMP,
             extracted_data = $1
         WHERE id = $2`,
        [JSON.stringify({
          error: 'OpenAI API key not configured. Please contact system administrator.'
        }), documentId]
      )
      return
    }

    // Convert PDF to images (one per page)
    console.log('üìÑ Convertendo PDF para imagens...')
    await updateProgress(documentId, 10, 'CONVERTING')

    const pdfBuffer = Buffer.isBuffer(fileData) ? fileData : fs.readFileSync(fileData)

    const pngPages = await pdfToPng(pdfBuffer, {
      disableFontFace: false,
      useSystemFonts: false,
      viewportScale: 3.0, // Higher resolution for better text recognition (increased from 2.0)
      outputFileMask: 'page'
    })

    console.log(`‚úÖ PDF convertido: ${pngPages.length} p√°ginas`)
    await updateProgress(documentId, 20, 'EXTRACTING')

    // Process each page with OCR + GPT
    console.log('üîç Processando p√°ginas com OCR + GPT...')
    const allProcedures: any[] = []

    for (let i = 0; i < pngPages.length; i++) {
      const pageNum = i + 1
      const progressPercent = 20 + Math.floor((i / pngPages.length) * 60)
      await updateProgress(documentId, progressPercent, 'EXTRACTING')

      console.log(`üìÑ Processando p√°gina ${pageNum}/${pngPages.length}...`)

      // Step 1: Extract text with OCR
      const imageBuffer = pngPages[i].content
      console.log(`   üî§ Extraindo texto com OCR...`)

      const { data: { text } } = await Tesseract.recognize(imageBuffer, 'por', {
        logger: () => {} // Silent logger
      })

      if (!text || text.trim().length < 50) {
        console.log(`   ‚ö†Ô∏è P√°gina ${pageNum}: Texto insuficiente extra√≠do por OCR`)
        continue
      }

      console.log(`   ‚úÖ OCR extraiu ${text.length} caracteres`)
      console.log(`   üìù Primeiros 300 chars do OCR: ${text.substring(0, 300)}`)

      // Step 2: Use GPT to parse the extracted text
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: 'Voc√™ √© um parser especializado em tabelas de procedimentos odontol√≥gicos. Extraia dados estruturados do texto fornecido SEM inventar informa√ß√µes.'
          },
          {
            role: 'user',
            content: `Analise este texto extra√≠do por OCR de uma tabela de procedimentos odontol√≥gicos e retorne um JSON estruturado.

TEXTO EXTRA√çDO:
${text}

INSTRU√á√ïES:
1. Encontre c√≥digos que come√ßam com "A" seguido de d√≠gitos e pontos (ex: A1.01.01.01, A2.02.01.01, A10.05.05.01)
   - Os c√≥digos podem estar em formatos variados: "A1.01.01.01", "A 1.01.01.01", "A1 01 01 01"
2. Para cada c√≥digo encontrado, extraia:
   - code: O c√≥digo normalizado (ex: A1.01.01.01)
   - description: O texto que vem AP√ìS o c√≥digo na mesma linha
   - value: O n√∫mero que representa valor monet√°rio (pode ter ‚Ç¨ ou R$). Se n√£o houver n√∫mero ou for "Sem CP", use null
3. **IMPORTANTE**: Use APENAS dados presentes no texto. N√£o invente c√≥digos ou descri√ß√µes.
4. Se uma linha tem c√≥digo mas n√£o consegue identificar descri√ß√£o, use o c√≥digo como descri√ß√£o tempor√°ria
5. Retorne APENAS JSON v√°lido no formato:

{
  "procedures": [
    {"code": "A1.01.01.01", "description": "Descri√ß√£o exata", "value": 130.00},
    {"code": "A1.01.01.02", "description": "Outra descri√ß√£o", "value": null}
  ]
}

Se n√£o encontrar procedimentos v√°lidos, retorne {"procedures": []}`
          }
        ],
        temperature: 0.0,
        response_format: { type: 'json_object' }
      })

      const pageResponse = response.choices[0].message.content || ''

      // Extract JSON from response
      try {
        const pageData = JSON.parse(pageResponse)
        if (pageData.procedures && Array.isArray(pageData.procedures)) {
          console.log(`   ‚úÖ Extra√≠dos ${pageData.procedures.length} procedimentos`)
          allProcedures.push(...pageData.procedures)
        }
      } catch (parseError) {
        console.error(`   ‚ùå Erro ao parsear JSON da p√°gina ${pageNum}:`, parseError.message)
      }
    }

    console.log(`\n‚úÖ Total extra√≠do: ${allProcedures.length} procedimentos de ${pngPages.length} p√°ginas`)

    // Deduplicate procedures by code (keep the one with highest combined confidence)
    const procedureMap = new Map()
    for (const proc of allProcedures) {
      const existing = procedureMap.get(proc.code)
      if (!existing) {
        procedureMap.set(proc.code, proc)
      } else {
        // Keep procedure with better description length and value (more complete)
        const existingScore = (existing.description?.length || 0) + (existing.value ? 1000 : 0)
        const newScore = (proc.description?.length || 0) + (proc.value ? 1000 : 0)
        if (newScore > existingScore) {
          procedureMap.set(proc.code, proc)
        }
      }
    }

    const uniqueProcedures = Array.from(procedureMap.values())
    console.log(`üîç Ap√≥s deduplica√ß√£o: ${uniqueProcedures.length} procedimentos √∫nicos (removidos ${allProcedures.length - uniqueProcedures.length} duplicados)`)

    const extractedData = { procedures: uniqueProcedures }

    // Update document with extracted data (NO classification, NO mappings)
    await client.query(
      `UPDATE insurance_provider_documents
       SET processed = true,
           processed_at = CURRENT_TIMESTAMP,
           processing_status = 'COMPLETED',
           processing_progress = 100,
           extracted_data = $1
       WHERE id = $2`,
      [JSON.stringify(extractedData), documentId]
    )

    console.log(`‚úÖ PDF processado com sucesso: ${documentId}`)
    console.log(`üìä ${uniqueProcedures.length} procedimentos extra√≠dos e salvos`)
    console.log(`‚è≠Ô∏è Pr√≥ximo passo: Usu√°rio far√° pareamento manual dos procedimentos`)

  } catch (error) {
    console.error('‚ùå Error in processPDFDocument:', error)
    console.error('Error stack:', error.stack)

    // Update document status to failed with error details
    await updateProgress(documentId, 0, 'FAILED')
    await client.query(
      `UPDATE insurance_provider_documents
       SET processing_status = 'FAILED',
           processed_at = CURRENT_TIMESTAMP,
           extracted_data = $1
       WHERE id = $2`,
      [JSON.stringify({
        error: error.message || 'Unknown error',
        stack: error.stack || '',
        timestamp: new Date().toISOString()
      }), documentId]
    )
  } finally {
    client.release()
  }
}

/**
 * Classify extracted procedures using AI (periciable and adults_only)
 */
async function classifyProceduresWithAI(extractedProcedures: any[]): Promise<any[]> {
  if (!openai) {
    console.warn('‚ö†Ô∏è OpenAI not available, skipping AI classification')
    return extractedProcedures.map(proc => ({
      ...proc,
      isPericiable: false,
      adultsOnly: false,
      aiPericiableConfidence: 0,
      aiAdultsOnlyConfidence: 0,
      reasoning: 'OpenAI not configured'
    }))
  }

  if (!extractedProcedures || extractedProcedures.length === 0) {
    return []
  }

  try {
    console.log(`üîç Classificando ${extractedProcedures.length} procedimentos (perici√°vel e adults_only)`)

    // Process in batches of 50 to avoid token limits
    const BATCH_SIZE = 50
    const allClassifications: any[] = []

    for (let i = 0; i < extractedProcedures.length; i += BATCH_SIZE) {
      const batch = extractedProcedures.slice(i, i + BATCH_SIZE)
      const batchNumber = Math.floor(i / BATCH_SIZE) + 1
      const totalBatches = Math.ceil(extractedProcedures.length / BATCH_SIZE)

      console.log(`üîÑ Processando lote ${batchNumber}/${totalBatches} (${batch.length} procedimentos)`)

      const prompt = `Voc√™ √© um especialista em procedimentos odontol√≥gicos e per√≠cias dent√°rias.

Sua tarefa √© CLASSIFICAR cada procedimento em duas categorias:

1. **PERICI√ÅVEL**: Procedimentos que normalmente requerem per√≠cia/avalia√ß√£o pr√©via pela seguradora
   - SIM: Procedimentos complexos, caros, est√©ticos, ou que envolvem pr√≥teses, implantes, ortodontia, cirurgias grandes
   - N√ÉO: Procedimentos simples, preventivos, emergenciais, diagn√≥sticos (consultas, radiografias, limpezas, restaura√ß√µes simples, extra√ß√µes simples)

2. **ADULTS_ONLY**: Procedimentos que s√≥ podem ser realizados em adultos (n√£o crian√ßas)
   - SIM: Procedimentos exclusivos para adultos (ex: implantes, pr√≥teses complexas, tratamentos periodontais avan√ßados)
   - N√ÉO: Procedimentos que podem ser feitos em qualquer idade (consultas, radiografias, restaura√ß√µes, extra√ß√µes, ortodontia)

PROCEDIMENTOS PARA CLASSIFICAR:
${JSON.stringify(batch, null, 2)}

INSTRU√á√ïES:
1. Analise CADA procedimento individualmente
2. Classifique como perici√°vel ou n√£o (true/false)
3. Classifique como adults_only ou n√£o (true/false)
4. Atribua um score de confian√ßa para cada classifica√ß√£o (0.0 a 1.0):
   - 0.95-1.0: Certeza absoluta
   - 0.80-0.94: Alta confian√ßa
   - 0.70-0.79: Confian√ßa m√©dia (ainda aceit√°vel)
   - 0.50-0.69: Baixa confian√ßa (requer revis√£o manual)
   - <0.50: Incerto (requer revis√£o manual)

RETORNE APENAS JSON PURO (sem markdown, sem coment√°rios) no formato:
{
  "classifications": [
    {
      "code": "c√≥digo do procedimento",
      "isPericiable": true/false,
      "periciableConfidence": 0.95,
      "adultsOnly": true/false,
      "adultsOnlyConfidence": 0.90,
      "reasoning": "breve explica√ß√£o"
    },
    ...
  ]
}

IMPORTANTE: O array "classifications" DEVE ter exatamente ${batch.length} elementos, na mesma ordem dos procedimentos recebidos.`

      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: 'Voc√™ √© um assistente especializado em classifica√ß√£o de procedimentos odontol√≥gicos. Sempre retorne JSON v√°lido sem markdown.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.1,
        response_format: { type: 'json_object' }
      })

      const content = response.choices[0].message.content
      if (!content) {
        throw new Error('Empty response from OpenAI')
      }

      // Parse and clean JSON
      let jsonText = content.trim()

      // Remove markdown code blocks
      jsonText = jsonText.replace(/```json\s*/g, '').replace(/```\s*/g, '')

      // Remove common phrases
      const phrasesToRemove = [
        /^Aqui est√°.*?:\s*/i,
        /^Aqui est√£o.*?:\s*/i,
        /^Segue.*?:\s*/i,
        /^Here is.*?:\s*/i,
        /^Here are.*?:\s*/i,
      ]
      for (const phrase of phrasesToRemove) {
        jsonText = jsonText.replace(phrase, '')
      }

      // Extract JSON object
      const firstBrace = jsonText.indexOf('{')
      const lastBrace = jsonText.lastIndexOf('}')
      if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
        jsonText = jsonText.substring(firstBrace, lastBrace + 1)
      }

      // Remove comments
      jsonText = jsonText.replace(/\/\/[^\n]*/g, '')
      jsonText = jsonText.replace(/\/\*[\s\S]*?\*\//g, '')
      jsonText = jsonText.replace(/,(\s*[}\]])/g, '$1')
      jsonText = jsonText.trim()

      const result = JSON.parse(jsonText)

      if (!result.classifications || !Array.isArray(result.classifications)) {
        throw new Error('Invalid response format from AI')
      }

      console.log(`‚úÖ Lote ${batchNumber}/${totalBatches}: ${result.classifications.length} procedimentos classificados`)
      allClassifications.push(...result.classifications)
    }

    console.log(`‚úÖ IA classificou todos os ${allClassifications.length} procedimentos`)

    // Merge AI classifications with extracted procedures
    const classifiedProcedures = extractedProcedures.map((proc, index) => {
      const aiClassification = allClassifications[index]

      if (!aiClassification) {
        return {
          ...proc,
          isPericiable: false,
          adultsOnly: false,
          aiPericiableConfidence: 0,
          aiAdultsOnlyConfidence: 0,
          reasoning: 'Sem classifica√ß√£o da IA'
        }
      }

      return {
        ...proc,
        isPericiable: aiClassification.isPericiable || false,
        adultsOnly: aiClassification.adultsOnly || false,
        aiPericiableConfidence: aiClassification.periciableConfidence || 0,
        aiAdultsOnlyConfidence: aiClassification.adultsOnlyConfidence || 0,
        reasoning: aiClassification.reasoning || 'Classifica√ß√£o autom√°tica por IA'
      }
    })

    // Log statistics
    const periciableCount = classifiedProcedures.filter(p => p.isPericiable).length
    const adultsOnlyCount = classifiedProcedures.filter(p => p.adultsOnly).length
    const highConfidenceCount = classifiedProcedures.filter(p =>
      p.aiPericiableConfidence >= 0.8 && p.aiAdultsOnlyConfidence >= 0.8
    ).length
    const needsReviewCount = classifiedProcedures.filter(p =>
      p.aiPericiableConfidence < 0.7 || p.aiAdultsOnlyConfidence < 0.7
    ).length

    console.log('üìä Resultados da classifica√ß√£o:')
    console.log(`   ‚Ä¢ ${periciableCount} procedimentos PERICI√ÅVEIS`)
    console.log(`   ‚Ä¢ ${adultsOnlyCount} procedimentos ADULTS ONLY`)
    console.log(`   ‚Ä¢ ${highConfidenceCount} com alta confian√ßa (‚â•80%)`)
    console.log(`   ‚Ä¢ ${needsReviewCount} requerem revis√£o manual (<70%)`)

    return classifiedProcedures

  } catch (error) {
    console.error('‚ùå Erro na classifica√ß√£o por IA:', error)
    console.error('Stack:', error.stack)
    console.error('Message:', error.message)

    // Fallback: return procedures without AI classification
    console.log('‚ö†Ô∏è Usando classifica√ß√£o padr√£o (sem IA) devido a erro')
    return extractedProcedures.map(proc => ({
      ...proc,
      isPericiable: false,
      adultsOnly: false,
      aiPericiableConfidence: 0,
      aiAdultsOnlyConfidence: 0,
      reasoning: `Erro na classifica√ß√£o: ${error.message || 'Unknown error'}`
    }))
  }
}

/**
 * GET /api/insurance/documents/:documentId/status
 * Get processing status for a document
 */
router.get('/documents/:documentId/status', authRequired, async (req, res) => {
  try {
    const { documentId } = req.params

    const result = await pool.query(
      `SELECT processing_progress, processing_stage, processing_status
       FROM insurance_provider_documents
       WHERE id = $1`,
      [documentId]
    )

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Documento n√£o encontrado' })
    }

    res.json(result.rows[0])
  } catch (error) {
    console.error('Error fetching document status:', error)
    res.status(500).json({ error: 'Erro ao buscar status do documento' })
  }
})

/**
 * GET /api/insurance/documents/:documentId
 * Get full document with extracted data
 */
router.get('/documents/:documentId', authRequired, async (req, res) => {
  try {
    const { documentId } = req.params

    const result = await pool.query(
      `SELECT id, insurance_provider_id, file_name, processing_status,
              processing_progress, extracted_data, created_at, processed_at
       FROM insurance_provider_documents
       WHERE id = $1`,
      [documentId]
    )

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Documento n√£o encontrado' })
    }

    res.json(result.rows[0])
  } catch (error) {
    console.error('Error fetching document:', error)
    res.status(500).json({ error: 'Erro ao buscar documento' })
  }
})

/**
 * GET /api/insurance/:providerId/documents
 * Get all documents for a provider
 */
router.get('/:providerId/documents', authRequired, async (req, res) => {
  try {
    const { providerId } = req.params
    const { clinicId } = req.query
    console.log(`üì• Fetching documents for provider: ${providerId}`)

    const result = await pool.query(
      `SELECT
        ipd.*,
        u.name as uploaded_by_name
       FROM insurance_provider_documents ipd
       LEFT JOIN users u ON ipd.created_by = u.id
       WHERE ipd.insurance_provider_id = $1
       ORDER BY ipd.created_at DESC`,
      [providerId]
    )

    console.log(`‚úÖ Found ${result.rows.length} documents for provider ${providerId}`)
    if (result.rows.length > 0) {
      console.log(`   Latest document: ${result.rows[0].id} (${result.rows[0].processing_status})`)
    }

    res.json(result.rows)
  } catch (error) {
    console.error('‚ùå Error fetching documents:', error)
    res.status(500).json({ error: 'Erro ao buscar documentos' })
  }
})

/**
 * GET /api/insurance/documents/:documentId/mappings
 * Get procedure mappings for a document
 */
router.get('/documents/:documentId/mappings', authRequired, async (req, res) => {
  try {
    const { documentId } = req.params
    console.log(`üì• Fetching mappings for document: ${documentId}`)

    const result = await pool.query(
      `SELECT
        pm.*,
        pbt.code as base_code,
        pbt.description as base_description,
        pbt.is_periciable as base_is_periciable,
        pbt.adults_only as base_adults_only,
        u.name as reviewed_by_name
       FROM procedure_mappings pm
       LEFT JOIN procedure_base_table pbt ON pm.mapped_procedure_base_id = pbt.id
       LEFT JOIN users u ON pm.reviewed_by = u.id
       WHERE pm.document_id = $1
       ORDER BY pm.extracted_procedure_code`,
      [documentId]
    )

    console.log(`‚úÖ Found ${result.rows.length} mappings for document ${documentId}`)

    // Ensure extracted_adults_only is included (for older records it might be null)
    result.rows.forEach(row => {
      if (row.extracted_adults_only === null || row.extracted_adults_only === undefined) {
        // If not set, use the base procedure's adults_only if mapped, otherwise default to false
        row.extracted_adults_only = row.base_adults_only || false
      }
    })

    res.json(result.rows)
  } catch (error) {
    console.error('‚ùå Error fetching mappings:', error)
    res.status(500).json({ error: 'Erro ao buscar mapeamentos' })
  }
})

/**
 * POST /api/insurance/mappings/:mappingId/approve
 * Approve a procedure mapping and create insurance provider procedure
 */
router.post('/mappings/:mappingId/approve', authRequired, async (req, res) => {
  const client = await pool.connect()

  try {
    await client.query('BEGIN')

    const { mappingId } = req.params
    const { providerId } = req.body

    // Get mapping details
    const mappingResult = await client.query(
      'SELECT * FROM procedure_mappings WHERE id = $1',
      [mappingId]
    )

    if (mappingResult.rows.length === 0) {
      await client.query('ROLLBACK')
      return res.status(404).json({ error: 'Mapeamento n√£o encontrado' })
    }

    const mapping = mappingResult.rows[0]

    // Create insurance provider procedure
    // Note: procedure_base_id can be NULL if no matching was done
    const procedureId = uuidv4()
    await client.query(
      `INSERT INTO insurance_provider_procedures (
        id, insurance_provider_id, procedure_base_id, provider_code,
        provider_description, is_periciable, max_value, active
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, true)`,
      [
        procedureId,
        providerId,
        mapping.mapped_procedure_base_id || null, // Allow NULL
        mapping.extracted_procedure_code,
        mapping.extracted_description,
        mapping.extracted_is_periciable || false,
        mapping.extracted_value || null
      ]
    )

    // Update mapping status
    await client.query(
      `UPDATE procedure_mappings
       SET status = 'APPROVED',
           mapped_provider_procedure_id = $1,
           reviewed_by = $2,
           reviewed_at = CURRENT_TIMESTAMP
       WHERE id = $3`,
      [procedureId, req.user.id, mappingId]
    )

    await client.query('COMMIT')

    res.json({ success: true, procedureId })
  } catch (error) {
    await client.query('ROLLBACK')
    console.error('Error approving mapping:', error)
    res.status(500).json({ error: 'Erro ao aprovar mapeamento' })
  } finally {
    client.release()
  }
})

/**
 * POST /api/insurance/mappings/:mappingId/update
 * Update a procedure mapping
 */
router.post('/mappings/:mappingId/update', authRequired, async (req, res) => {
  try {
    const { mappingId } = req.params
    const { mappedProcedureBaseId, status, notes, extractedIsPericiable, extractedAdultsOnly } = req.body

    await pool.query(
      `UPDATE procedure_mappings
       SET mapped_procedure_base_id = $1,
           status = $2,
           notes = $3,
           extracted_is_periciable = COALESCE($4, extracted_is_periciable),
           extracted_adults_only = COALESCE($5, extracted_adults_only),
           reviewed_by = $6,
           reviewed_at = CURRENT_TIMESTAMP
       WHERE id = $7`,
      [
        mappedProcedureBaseId,
        status || 'PENDING',
        notes || null,
        extractedIsPericiable !== undefined ? extractedIsPericiable : null,
        extractedAdultsOnly !== undefined ? extractedAdultsOnly : null,
        req.user.id,
        mappingId
      ]
    )

    res.json({ success: true })
  } catch (error) {
    console.error('Error updating mapping:', error)
    res.status(500).json({ error: 'Erro ao atualizar mapeamento' })
  }
})

export default router
